{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --user google-cloud-aiplatform Pillow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart the runtime\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"alexbu-gke-dev-d\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from vertexai.preview.vision_models import ImageGenerationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "\n",
    "import IPython.display\n",
    "from PIL import Image as PIL_Image\n",
    "from PIL import ImageOps as PIL_ImageOps\n",
    "\n",
    "\n",
    "def display_image(\n",
    "    image,\n",
    "    max_width: int = 600,\n",
    "    max_height: int = 350,\n",
    ") -> None:\n",
    "    pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
    "    if pil_image.mode != \"RGB\":\n",
    "        # RGB is supported by all Jupyter environments (e.g. RGBA is not yet)\n",
    "        pil_image = pil_image.convert(\"RGB\")\n",
    "    image_width, image_height = pil_image.size\n",
    "    if max_width < image_width or max_height < image_height:\n",
    "        # Resize to display a smaller notebook image\n",
    "        pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
    "    IPython.display.display(pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_model = ImageGenerationModel.from_pretrained(\"imagen-3.0-generate-001\")\n",
    "generation_model_fast = ImageGenerationModel.from_pretrained(\n",
    "    \"imagen-3.0-fast-generate-001\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "prompt = \"\"\"\n",
    "a photorealistic image of the inside of an amethyst crystal on display in a museum\n",
    "\"\"\"\n",
    "\n",
    "# Imagen 3 image generation\n",
    "image = generation_model.generate_images(\n",
    "    prompt=prompt,\n",
    "    number_of_images=1,\n",
    "    aspect_ratio=\"3:4\",\n",
    "    safety_filter_level=\"block_some\",\n",
    "    person_generation=\"allow_adult\",\n",
    ")\n",
    "\n",
    "# Imagen 3 Fast image generation\n",
    "fast_image = generation_model_fast.generate_images(\n",
    "    prompt=prompt,\n",
    "    number_of_images=1,\n",
    "    aspect_ratio=\"3:4\",\n",
    "    safety_filter_level=\"block_some\",\n",
    "    person_generation=\"allow_adult\",\n",
    ")\n",
    "\n",
    "# Display generated images\n",
    "fig, axis = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axis[0].imshow(image[0]._pil_image)\n",
    "axis[0].set_title(\"Imagen 3\")\n",
    "axis[1].imshow(fast_image[0]._pil_image)\n",
    "axis[1].set_title(\"Imagen 3 Fast\")\n",
    "for ax in axis:\n",
    "    ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code to generate the prompt:\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "Install the Google AI Python SDK\n",
    "\n",
    "$ pip install google-generativeai\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 64,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-pro\",\n",
    "  generation_config=generation_config,\n",
    "  # safety_settings = Adjust safety settings\n",
    "  # See https://ai.google.dev/gemini-api/docs/safety-settings\n",
    ")\n",
    "\n",
    "chat_session = model.start_chat(\n",
    "  history=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"parts\": [\n",
    "        \"Generate a prompt that I can pass to image generation model, like \\\"imagen\\\" to generate an image of hint to display next to Chinese word \\\"包\\\" pinyin \\\"bāo\\\" translated as \\\"package\\\" in a language learning app. The hint should be subtle without revealing the image. Generate the prompt text only.\",\n",
    "      ],\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"model\",\n",
    "      \"parts\": [\n",
    "        \"A brown paper package tied up with string, but zoomed in extremely close on the knotted string so the contents are obscured and only the texture of the string and paper are visible.  Add a subtle warm, inviting light. \\n\",\n",
    "      ],\n",
    "    },\n",
    "  ]\n",
    ")\n",
    "\n",
    "response = chat_session.send_message(\"INSERT_INPUT_HERE\")\n",
    "\n",
    "print(response.text)\n",
    "\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
